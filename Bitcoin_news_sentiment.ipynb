{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bitcoin_news_sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvqX8hyJL6X3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "36831da8-fd11-4432-a771-3e8349117e99"
      },
      "source": [
        "pip install newsapi-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newsapi-python\n",
            "  Downloading https://files.pythonhosted.org/packages/de/9e/9050199ac7cbc755d1c49577fdaa5517901124b574264b3602a8b8028440/newsapi_python-0.2.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from newsapi-python) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (3.0.4)\n",
            "Installing collected packages: newsapi-python\n",
            "Successfully installed newsapi-python-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEtA0EYBMEEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "89982f2e-508b-4974-98f6-573b6ecd5977"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import pickle"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h20EpQO3MSnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Don't run this cell, it only consists of 31 days data, fetch news data with news api\n",
        "## set api_key for news api\n",
        "newsapi = NewsApiClient(api_key='3486e577627249b2b78a602bf7ab4ebc')\n",
        "\n",
        "## create the list of dates\n",
        "base = datetime.datetime.today()\n",
        "date_list = [base - datetime.timedelta(days=x) for x in range(0, 31)]\n",
        "date_strings = [dt.strftime('%Y-%m-%d') for dt in date_list]\n",
        "\n",
        "## import nltk pre-trained sentiment analyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "## fetch news and perform sentiment analysis on their descriptions\n",
        "descriptions_date = {}\n",
        "descriptions_polaritys = {}\n",
        "descriptions_context = []\n",
        "\n",
        "for date_str in date_strings:\n",
        "    descriptions = []\n",
        "    polaritys = []\n",
        "    general_polarity = {'neg': 0.0, 'pos': 0.0}\n",
        "    all_articles = newsapi.get_everything(q='bitcoin', from_param=date_str, to=date_str, language='en')\n",
        "    for i in range(len(all_articles['articles'])):\n",
        "        description = all_articles['articles'][i]['description']\n",
        "        if description:\n",
        "            non_symbols = re.sub(r'[^\\w]', ' ', description) # remove symbols\n",
        "            non_digits = re.sub(r'\\d+', ' ', non_symbols) # remove digits\n",
        "            one_space = re.sub(' +', ' ', non_digits) # remove extra whitespaces\n",
        "            description_lower = one_space.lower() # transform characters into lower-case\n",
        "            description_words = ' '.join(w for w in description_lower.split() if len(w)>1) # remove single characters\n",
        "            descriptions.append(description_words) # save descriptions context\n",
        "            polarity = sid.polarity_scores(description_words)\n",
        "            #save descriptions polarity\n",
        "            for polar in ['neg', 'pos']:\n",
        "              general_polarity[polar] += polarity[polar]\n",
        "            descriptions_context.append(description_words)\n",
        "    descriptions_date[date_str] = descriptions\n",
        "    descriptions_polaritys[date_str] = max(general_polarity, key=general_polarity.get)\n",
        "descriptions_polaritys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7Rm2LkGSV3U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc83fadb-06df-44ac-f243-f1ab85f3c26e"
      },
      "source": [
        "# fetch data with ContextualWeb api\n",
        "## create the list of dates\n",
        "base = datetime.datetime.today()\n",
        "date_list = [base - datetime.timedelta(days=x) for x in range(0, 220)]\n",
        "date_strings = [dt.strftime('%Y-%m-%d') for dt in date_list]\n",
        "\n",
        "## import nltk pre-trained sentiment analyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "## fetch news and perform sentiment analysis on their descriptions\n",
        "descriptions_date = {}\n",
        "descriptions_polaritys = {}\n",
        "descriptions_context = []\n",
        "\n",
        "url = \"https://contextualwebsearch-websearch-v1.p.rapidapi.com/api/Search/NewsSearchAPI\"\n",
        "querystring = {\"autoCorrect\":\"false\",\"pageNumber\":\"1\",\"pageSize\":\"10\",\"q\":\"Bitcoin\",\"safeSearch\":\"false\", \"fromPublishedDate\":\"2020-1-1\", \"toPublishedDate\":\"2020-1-2\"}\n",
        "headers = {\n",
        "    'x-rapidapi-host': \"contextualwebsearch-websearch-v1.p.rapidapi.com\",\n",
        "    'x-rapidapi-key': \"6e64d32139msh66d110fec2ee5d6p1b2f8ajsn506563d39c4e\"\n",
        "    }\n",
        "\n",
        "for idx in range(len(date_strings)-1):\n",
        "    descriptions = []\n",
        "    polaritys = []\n",
        "    general_polarity = {'neg': 0.0, 'pos': 0.0}\n",
        "    querystring['fromPublishedDate'] = date_strings[idx+1]\n",
        "    querystring['toPublishedDate'] = date_strings[idx]\n",
        "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
        "    response_json = response.json()['value']\n",
        "    for i in range(len(response_json)):\n",
        "        description = response_json[i]['description']\n",
        "        if description:\n",
        "            non_symbols = re.sub(r'[^\\w]', ' ', description) # remove symbols\n",
        "            non_digits = re.sub(r'\\d+', ' ', non_symbols) # remove digits\n",
        "            one_space = re.sub(' +', ' ', non_digits) # remove extra whitespaces\n",
        "            description_lower = one_space.lower() # transform characters into lower-case\n",
        "            description_words = ' '.join(w for w in description_lower.split() if len(w)>1) # remove single characters\n",
        "            descriptions.append(description_words) # save descriptions context\n",
        "            polarity = sid.polarity_scores(description_words)\n",
        "            #save descriptions polarity\n",
        "            for polar in ['neg', 'pos']:\n",
        "              general_polarity[polar] += polarity[polar]\n",
        "            descriptions_context.append(description_words)\n",
        "    descriptions_date[date_strings[idx+1]] = descriptions\n",
        "    descriptions_polaritys[date_strings[idx+1]] = max(general_polarity, key=general_polarity.get)\n",
        "\n",
        "## save news data and their polarities\n",
        "f = open(\"./drive/My Drive/final_project/file.pkl\", \"wb\")\n",
        "pickle.dump(descriptions_date, f)\n",
        "f.close()\n",
        "\n",
        "f = open(\"./drive/My Drive/final_project/polarities.pkl\", \"wb\")\n",
        "pickle.dump(descriptions_polaritys, f)\n",
        "f.close()"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2020-01-31', '2020-01-30', '2020-01-29', '2020-01-28', '2020-01-27']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp0GLf4Wkt4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}